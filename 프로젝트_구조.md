# CASPIAN 프로젝트 구조 및 파일 역할

## 📁 전체 디렉토리 구조

```
carbon/
│
├── 📂 hub/                        # Hub Cluster 구현 (핵심)
│   ├── __init__.py
│   ├── app.py                    # Hub API 서버
│   ├── models.py                 # 데이터 모델
│   ├── store.py                  # 데이터 저장소
│   ├── scheduler.py              # CASPIAN 스케줄러
│   └── dispatcher.py             # Kubernetes 디스패처
│
├── 📂 app/                        # 공유 컴포넌트
│   ├── __init__.py
│   ├── optimizer.py              # CASPIAN MILP 최적화
│   ├── schemas.py                # Pydantic 스키마
│   ├── carbon_client.py          # 탄소 데이터 수집
│   ├── metrics.py                # Prometheus 메트릭
│   ├── requirements.txt          # Python 의존성
│   └── tests/                    # 테스트
│       ├── __init__.py
│       ├── test_carbon_client.py
│       └── test_main.py
│
├── 📂 clusters/                   # Kind 클러스터 설정
│   ├── cluster-kr.yaml           # 한국 클러스터 설정
│   ├── cluster-jp.yaml           # 일본 클러스터 설정
│   └── cluster-cn.yaml           # 중국 클러스터 설정
│
├── 📂 dashboards/                 # Grafana 대시보드
│   ├── carbon_dashboard.json     # 레거시 대시보드
│   └── carbon-hub-dashboard.json # Hub 대시보드 (현재 사용)
│
├── 📂 grafana/                    # Grafana 프로비저닝
│   └── provisioning/
│       ├── datasources/
│       │   └── prometheus.yml    # Prometheus 데이터소스
│       └── dashboards/
│           └── dashboard.yml     # 대시보드 프로비저닝 설정
│
├── 📂 k8s/                        # Kubernetes 매니페스트
│   ├── deployment.yaml           # 앱 배포
│   ├── operator-deployment.yaml  # Operator 배포
│   ├── operator-rbac.yaml        # Operator RBAC
│   ├── prometheus-scrape.yaml    # Prometheus ServiceMonitor
│   └── all-in-one.yaml           # 통합 배포
│
├── 📂 operator/                   # Kubernetes Operator (미사용)
│   ├── Dockerfile
│   ├── operator.py
│   └── tests/
│       ├── __init__.py
│       └── test_operator.py
│
├── 📂 .claude/                    # Claude Code 설정
│   └── settings.local.json
│
├── 🚀 start-caspian.sh           # 완전 자동 시작 스크립트 (Linux/Mac)
├── 🚀 start-caspian.bat          # 완전 자동 시작 스크립트 (Windows)
├── 🛑 stop-caspian.sh            # 시스템 종료 스크립트
├── ⚙️ setup-spoke-clusters.sh    # Spoke 클러스터 생성
│
├── 🐳 docker-compose.yml         # Docker Compose 설정
├── 🐳 Dockerfile                 # Hub 컨테이너 이미지
├── 📊 prometheus.yml             # Prometheus 설정
├── 🔧 kubeconfig-docker          # Docker용 kubeconfig (생성됨)
│
├── 📖 README.md                  # 메인 문서
├── 📖 QUICKSTART.md              # 빠른 시작 가이드
├── 📖 시동_가이드.md             # 상세 시동 가이드
├── 📖 시스템_완료_보고서.md      # 시스템 현황 보고서
├── 📖 HUB_SPOKE_구현_가이드.md   # Hub-Spoke 구현 가이드
├── 📖 CASPIAN_알고리즘_설명.md   # 알고리즘 설명
├── 📖 프로젝트_파일_구조.md      # 파일 구조 (레거시)
├── 📖 CASPIAN_최적화_이유.md     # 최적화 이유 설명
├── 📖 마이그레이션_가이드.md     # 마이그레이션 가이드
├── 📖 scheduling_sample.md       # 원본 스케줄링 샘플
│
├── 🧪 test_caspian.py            # 통합 테스트
├── 🧪 test-job-kr.yaml           # 테스트 Job (KR)
├── 🧪 test-job-jp.yaml           # 테스트 Job (JP)
├── 🧪 test-job-cn.yaml           # 테스트 Job (CN)
│
├── 📜 dev-run.sh                 # 개발 실행 스크립트 (레거시)
├── 📜 run_local.sh               # 로컬 실행 스크립트 (레거시)
├── 📜 start-hub-spoke.sh         # Hub-Spoke 시작 (레거시)
└── 📜 start-system.bat           # 시스템 시작 (레거시)
```

---

## 🎯 핵심 디렉토리 상세 설명

### 📂 `hub/` - Hub Cluster 구현 (가장 중요)

Hub-Spoke 아키텍처의 중앙 허브 클러스터 구현

#### `hub/app.py` (485줄)
**역할**: Hub Cluster의 FastAPI 서버
**포트**: 8080
**주요 기능**:
- ClusterInfo 관리 API (`/hub/clusters`)
- AppWrapper 관리 API (`/hub/appwrappers`)
- 수동 스케줄링/디스패치 트리거 (`/hub/schedule`, `/hub/dispatch`)
- 시스템 통계 (`/hub/stats`)
- Prometheus 메트릭 노출 (`/metrics`)
- Carbon Client 통합 (탄소 강도 자동 업데이트)

**핵심 엔드포인트**:
```python
POST   /hub/clusters        # Spoke 클러스터 등록
GET    /hub/clusters        # 클러스터 목록
POST   /hub/appwrappers     # AppWrapper 제출
GET    /hub/appwrappers     # AppWrapper 목록
POST   /hub/schedule        # 스케줄링 트리거
POST   /hub/dispatch        # 디스패치 트리거
GET    /hub/stats           # 시스템 통계
GET    /metrics             # Prometheus 메트릭
```

#### `hub/models.py` (150줄)
**역할**: Hub 데이터 모델 정의
**주요 모델**:
- `ClusterInfo`: Spoke 클러스터 정보 (geolocation, carbon_intensity, resources)
- `ClusterResources`: 클러스터 리소스 (CPU, 메모리, GPU)
- `AppWrapper`: Job 래퍼 (spec + status)
- `AppWrapperSpec`: Job 명세 (target_cluster, dispatching_gates)
- `AppWrapperStatus`: Job 상태 (phase, dispatched, cluster)
- `DispatchingGate`: 배포 게이트 (sustainability-gate)
- `GateStatus`: 게이트 상태 (OPEN/CLOSED)

**데이터 흐름**:
```
AppWrapperSpec → HubScheduler → targetCluster 결정 → gate OPEN
                                                    ↓
                                            HubDispatcher → Kubernetes Job
```

#### `hub/store.py` (200줄)
**역할**: Hub의 인메모리 데이터 저장소
**저장 데이터**:
- `_appwrappers`: Dict[str, AppWrapper] - Job ID → AppWrapper
- `_clusters`: Dict[str, ClusterInfo] - 클러스터 이름 → ClusterInfo

**주요 메서드**:
```python
# AppWrapper 관리
add_appwrapper(appwrapper)           # 추가
get_appwrapper(job_id)               # 조회
update_appwrapper(job_id, updates)   # 업데이트
get_pending_appwrappers()            # 대기 중 조회
get_dispatching_ready_appwrappers()  # 디스패치 준비됨 조회

# ClusterInfo 관리
update_cluster_info(cluster_info)    # 등록/업데이트
get_cluster_info(name)               # 조회
get_all_cluster_info()               # 전체 조회

# 통계
get_stats()                          # 시스템 통계
```

**특징**: asyncio.Lock으로 동시성 제어

#### `hub/scheduler.py` (280줄)
**역할**: CASPIAN 스케줄러 - 3단계 스케줄링 프로세스
**실행 주기**: 5분마다 자동 실행 (설정 가능)

**3단계 프로세스**:
```python
async def run_scheduling_cycle():
    # Step 1: Collect - Spoke 클러스터 정보 수집
    cluster_infos = await _collect_cluster_info()
    # carbon_intensity, resources 수집

    # Step 2: Optimize - CASPIAN 최적화 실행
    decisions = await _call_optimizer(appwrappers, cluster_infos)
    # MILP 솔버로 최적 배치 결정

    # Step 3: Update - AppWrapper 업데이트
    await _update_appwrappers(decisions)
    # targetCluster 설정, gate OPEN
```

**변환 로직**:
- Hub의 ClusterInfo → Optimizer의 ClusterCapacity
- Hub의 AppWrapper → Optimizer의 JobSpec
- Optimizer의 결과 → AppWrapper 업데이트

#### `hub/dispatcher.py` (250줄)
**역할**: Kubernetes Job 디스패처
**실행 주기**: 30초마다 자동 실행 (설정 가능)

**디스패치 프로세스**:
```python
async def run_dispatch_cycle():
    # 1. gate=OPEN인 AppWrapper 찾기
    ready_appwrappers = await hub_store.get_dispatching_ready_appwrappers()

    # 2. 각 AppWrapper를 Kubernetes에 배포
    for appwrapper in ready_appwrappers:
        cluster_info = await hub_store.get_cluster_info(target_cluster)

        # 3. Kubernetes Job 매니페스트 생성
        job_manifest = _create_job_manifest(appwrapper)

        # 4. kubectl context 전환 후 배포
        batch_api = _get_k8s_client(cluster_info.kubeconfig_context)
        batch_api.create_namespaced_job(namespace="default", body=job_manifest)

        # 5. AppWrapper 상태 업데이트
        appwrapper.status.dispatched = True
        appwrapper.status.phase = "Running"
```

**특징**: kubeconfig의 context를 사용하여 멀티 클러스터 접근

---

### 📂 `app/` - 공유 컴포넌트

Hub와 레거시 시스템 모두 사용하는 핵심 로직

#### `app/optimizer.py` (400줄)
**역할**: CASPIAN MILP 최적화 알고리즘
**프레임워크**: PuLP (Python Linear Programming)
**솔버**: CBC (COIN-OR Branch and Cut)

**목적 함수**:
```python
minimize: Σ (carbon_intensity × energy_consumption) + migration_cost
```

**제약 조건**:
1. 각 Job은 정확히 한 번만 스케줄링
2. 클러스터 리소스 용량 제한 (CPU, 메모리)
3. 시간 윈도우 제약 (release_slot, deadline_slot)
4. Affinity 제약 (선호 클러스터)

**입력/출력**:
```python
# 입력
OptimizeInput(
    jobs: List[JobSpec],
    clusters: List[ClusterCapacity],
    carbon_intensities: List[CarbonPoint],
    time_horizon: int
)

# 출력
OptimizeOutput(
    schedule: List[ScheduleDecision],
    total_carbon_g: float,
    optimal: bool
)
```

#### `app/schemas.py` (150줄)
**역할**: Pydantic 데이터 스키마 (타입 검증)

**주요 스키마**:
```python
JobSpec            # Job 명세
ClusterCapacity    # 클러스터 용량
CarbonPoint        # 탄소 강도 데이터
OptimizeInput      # 최적화 입력
OptimizeOutput     # 최적화 출력
ScheduleDecision   # 스케줄링 결정
```

#### `app/carbon_client.py` (300줄)
**역할**: 탄소 강도 데이터 수집 클라이언트

**데이터 소스**:
- **실제**: ElectricityMap API (환경변수 `USE_MOCK_DATA=false`)
- **Mock**: 랜덤 시뮬레이션 (기본값 `USE_MOCK_DATA=true`)

**기능**:
```python
# 멀티 존 모니터링
start_polling(zones: List[str])  # ["KR", "JP", "CN"]

# 10초마다 자동 업데이트
latest_data: Dict[str, Dict]  # {"KR": {"carbonIntensity": 350, ...}}
```

**Mock 데이터 범위**:
- KR: 300-400 gCO2/kWh
- JP: 350-500 gCO2/kWh
- CN: 500-750 gCO2/kWh

#### `app/metrics.py` (95줄)
**역할**: Prometheus 메트릭 정의

**메트릭 목록**:
```python
# 탄소 강도
grid_carbon_intensity_gco2_per_kwh{zone}

# AppWrapper 통계
appwrappers_total
appwrappers_pending
appwrappers_running
appwrappers_completed

# 클러스터 통계
clusters_total
clusters_ready

# API 요청
api_requests_total{endpoint, method, status}
```

---

## 🚀 시작 스크립트

### `start-caspian.sh` (400줄)
**역할**: 완전 자동 시작 스크립트
**플랫폼**: Linux, Mac, Windows Git Bash

**자동화 내용**:
1. 기존 환경 정리 (Docker 컨테이너, Kind 클러스터)
2. Spoke 클러스터 3개 생성 (carbon-kr, carbon-jp, carbon-cn)
3. Docker용 kubeconfig 생성 및 API 주소 변환
4. Docker Compose 서비스 시작 (Hub, Prometheus, Grafana)
5. Hub API 준비 대기 (최대 60초)
6. Spoke 클러스터 자동 등록
7. 시스템 상태 확인 및 출력

**예쁜 출력**:
- 색상 코딩 (GREEN, BLUE, YELLOW, RED)
- 프로그레스 바
- 단계별 진행 상황

**사용법**:
```bash
bash start-caspian.sh
```

### `stop-caspian.sh` (70줄)
**역할**: 시스템 종료 스크립트

**기능**:
1. Docker 컨테이너 종료
2. Kind 클러스터 삭제 옵션 제공 (사용자 선택)

### `setup-spoke-clusters.sh` (150줄)
**역할**: Kind 클러스터 생성 스크립트

**생성 클러스터**:
- carbon-kr: 1 control-plane + 2 workers
- carbon-jp: 1 control-plane + 2 workers
- carbon-cn: 1 control-plane + 2 workers

---

## 🐳 Docker 관련

### `docker-compose.yml`
**서비스 구성**:
```yaml
services:
  hub:            # Hub Cluster API (포트 8080)
  prometheus:     # 메트릭 수집 (포트 9090)
  grafana:        # 대시보드 (포트 3000)

networks:
  carbon-network: # 서비스 간 통신
  kind:           # Kind 클러스터 연결 (external)
```

**Hub 환경변수**:
- `ELECTRICITYMAP_API_KEY`: ElectricityMap API 키
- `CARBON_ZONES`: 모니터링할 지역 (KR,JP,CN)
- `USE_MOCK_DATA`: Mock 데이터 사용 여부 (true/false)
- `KUBECONFIG`: kubeconfig 파일 경로
- `SCHEDULER_INTERVAL`: 스케줄러 실행 주기 (초)
- `DISPATCHER_INTERVAL`: 디스패처 실행 주기 (초)

### `Dockerfile`
**베이스 이미지**: python:3.11-slim

**빌드 내용**:
1. app/requirements.txt 설치
2. app/ 디렉토리 복사
3. hub/ 디렉토리 복사
4. .kube 디렉토리 생성

### `prometheus.yml`
**스크레이프 설정**:
```yaml
scrape_configs:
  - job_name: 'hub-cluster'
    static_configs:
      - targets: ['hub:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

---

## 📊 Grafana 관련

### `dashboards/carbon-hub-dashboard.json`
**현재 사용 중인 대시보드**

**패널 구성** (10개):
1. Korea Carbon Intensity (Gauge)
2. Japan Carbon Intensity (Gauge)
3. China Carbon Intensity (Gauge)
4. Carbon Intensity Over Time (Time Series)
5. Total AppWrappers (Stat)
6. Pending AppWrappers (Stat)
7. Running AppWrappers (Stat)
8. Completed AppWrappers (Stat)
9. Total Clusters (Stat)
10. Ready Clusters (Stat)

**자동 리프레시**: 5초

### `grafana/provisioning/datasources/prometheus.yml`
**Prometheus 데이터소스 자동 설정**:
```yaml
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    isDefault: true
```

### `grafana/provisioning/dashboards/dashboard.yml`
**대시보드 자동 프로비저닝**:
```yaml
providers:
  - name: 'Carbon Aware Dashboards'
    folder: ''
    type: file
    options:
      path: /etc/grafana/provisioning/dashboards/files
```

---

## 📖 문서 파일

### 필수 문서 (읽기 순서)

1. **`QUICKSTART.md`** (1분)
   - 초간단 시작 가이드
   - 한 페이지에 모든 것

2. **`README.md`** (5분)
   - 프로젝트 개요
   - 빠른 시작
   - 사용 예시
   - 전체 참조

3. **`시동_가이드.md`** (필요시)
   - 상세 시작 방법
   - 수동 시작 방법
   - 트러블슈팅
   - 로그 확인

### 참고 문서

4. **`시스템_완료_보고서.md`**
   - 구현 완료 내용
   - 현재 시스템 상태
   - 테스트 결과
   - 메트릭 정보

5. **`HUB_SPOKE_구현_가이드.md`**
   - Hub-Spoke 아키텍처 상세
   - 구현 내용
   - API 문서

6. **`CASPIAN_알고리즘_설명.md`**
   - MILP 최적화 알고리즘
   - 수학적 모델
   - 제약 조건

7. **`마이그레이션_가이드.md`**
   - 레거시에서 Hub-Spoke로 전환
   - 파일 정리 가이드

8. **`scheduling_sample.md`**
   - 원본 스케줄링 샘플 (참고용)

---

## 🧪 테스트 파일

### `test_caspian.py`
**역할**: 통합 테스트
**테스트 항목**:
- CASPIAN 최적화 알고리즘
- 멀티 클러스터 스케줄링
- 탄소 강도 기반 배치

### `test-job-*.yaml`
**역할**: Kubernetes Job 테스트 매니페스트
- `test-job-kr.yaml`: 한국 클러스터용
- `test-job-jp.yaml`: 일본 클러스터용
- `test-job-cn.yaml`: 중국 클러스터용

---

## 🗑️ 레거시 파일 (사용하지 않음)

### 삭제된 파일
- ~~`app/main.py`~~ → `hub/app.py`로 대체
- ~~`app/job_store.py`~~ → `hub/store.py`로 대체
- ~~`app/k8s_client.py`~~ → `hub/dispatcher.py`로 대체
- ~~`app/dispatcher.py`~~ → `hub/dispatcher.py`로 대체

### 보관된 레거시
- `dev-run.sh`: 개발 실행 스크립트 (사용 안 함)
- `run_local.sh`: 로컬 실행 스크립트 (사용 안 함)
- `start-hub-spoke.sh`: 구버전 시작 스크립트 (사용 안 함)
- `start-system.bat`: 구버전 Windows 스크립트 (사용 안 함)
- `dashboards/carbon_dashboard.json`: 구버전 대시보드 (사용 안 함)

**권장**: 레거시 파일은 삭제해도 무방

### `operator/` 디렉토리
**상태**: 미구현 / 미사용
**내용**: Kubernetes Operator 구현 (향후 계획)

### `k8s/` 디렉토리
**상태**: 참고용
**내용**: Kubernetes 배포 매니페스트 (현재는 Hub가 동적 생성)

---

## 🔑 핵심 파일 요약

### 반드시 유지해야 할 파일

| 파일 | 역할 | 중요도 |
|------|------|--------|
| `hub/app.py` | Hub API 서버 | ⭐⭐⭐⭐⭐ |
| `hub/scheduler.py` | CASPIAN 스케줄러 | ⭐⭐⭐⭐⭐ |
| `hub/dispatcher.py` | Kubernetes 디스패처 | ⭐⭐⭐⭐⭐ |
| `hub/store.py` | 데이터 저장소 | ⭐⭐⭐⭐⭐ |
| `hub/models.py` | 데이터 모델 | ⭐⭐⭐⭐⭐ |
| `app/optimizer.py` | MILP 최적화 | ⭐⭐⭐⭐⭐ |
| `app/carbon_client.py` | 탄소 데이터 수집 | ⭐⭐⭐⭐⭐ |
| `app/metrics.py` | Prometheus 메트릭 | ⭐⭐⭐⭐ |
| `app/schemas.py` | 데이터 스키마 | ⭐⭐⭐⭐ |
| `start-caspian.sh` | 자동 시작 스크립트 | ⭐⭐⭐⭐⭐ |
| `docker-compose.yml` | Docker 설정 | ⭐⭐⭐⭐⭐ |
| `Dockerfile` | 컨테이너 이미지 | ⭐⭐⭐⭐ |
| `prometheus.yml` | Prometheus 설정 | ⭐⭐⭐ |
| `dashboards/carbon-hub-dashboard.json` | Grafana 대시보드 | ⭐⭐⭐⭐ |

---

## 📊 파일 통계

```
총 파일 수: ~60개
Python 코드: ~15개 (hub/ + app/)
문서: ~10개 (.md)
설정: ~10개 (.yml, .yaml, .json)
스크립트: ~8개 (.sh, .bat)
테스트: ~5개
```

**코드 라인 수**:
- hub/: ~1,365 줄
- app/: ~1,150 줄
- 스크립트: ~600 줄
- **총**: ~3,000 줄

---

## 🎯 디렉토리별 용도

| 디렉토리 | 용도 | 상태 |
|----------|------|------|
| `hub/` | Hub Cluster 구현 | ✅ 사용 중 |
| `app/` | 공유 컴포넌트 | ✅ 사용 중 |
| `dashboards/` | Grafana 대시보드 | ✅ 사용 중 |
| `grafana/` | Grafana 프로비저닝 | ✅ 사용 중 |
| `clusters/` | Kind 클러스터 설정 | ✅ 사용 중 |
| `k8s/` | K8s 매니페스트 | 📂 참고용 |
| `operator/` | K8s Operator | ❌ 미사용 |

---

## 🔄 데이터 흐름

```
1. 사용자 → Hub API (POST /hub/appwrappers)
   ↓
2. HubStore에 AppWrapper 저장 (phase: Pending)
   ↓
3. HubScheduler (5분마다)
   - ClusterInfo 수집 (carbon_intensity, resources)
   - CASPIAN Optimizer 호출 (MILP)
   - AppWrapper 업데이트 (targetCluster, gate=OPEN)
   ↓
4. HubDispatcher (30초마다)
   - gate=OPEN인 AppWrapper 찾기
   - Kubernetes Job 생성
   - Spoke 클러스터에 배포
   - AppWrapper 상태 업데이트 (phase: Running)
   ↓
5. Prometheus
   - Hub /metrics 수집 (10초마다)
   ↓
6. Grafana
   - Prometheus 데이터 시각화 (5초마다 갱신)
```

---

## 🚀 실행 프로세스

### 시작 시
```bash
bash start-caspian.sh
  ↓
1. Docker 컨테이너 정리
2. Kind 클러스터 생성 (carbon-kr, carbon-jp, carbon-cn)
3. kubeconfig 생성 및 변환
4. Docker Compose 시작 (hub, prometheus, grafana)
5. Hub API 대기
6. ClusterInfo 등록
  ↓
시스템 준비 완료!
```

### 런타임
```
Hub API (8080) ─────────┐
  ↓ (5분마다)           │
HubScheduler            │
  ↓                     │
CASPIAN Optimizer       │
  ↓                     │
AppWrapper 업데이트      │
  ↓ (30초마다)          │
HubDispatcher           │
  ↓                     │
Kubernetes Job 배포 ────┘
  ↓
Spoke Clusters (KR, JP, CN)
```

---

## 💡 파일 찾기 팁

### Hub 관련
- API 엔드포인트: `hub/app.py`
- 스케줄링 로직: `hub/scheduler.py`
- Job 배포: `hub/dispatcher.py`
- 데이터 모델: `hub/models.py`

### 최적화 관련
- MILP 알고리즘: `app/optimizer.py`
- 스키마: `app/schemas.py`

### 모니터링 관련
- 탄소 데이터: `app/carbon_client.py`
- 메트릭: `app/metrics.py`
- Grafana 대시보드: `dashboards/carbon-hub-dashboard.json`

### 설정 관련
- Docker: `docker-compose.yml`, `Dockerfile`
- Prometheus: `prometheus.yml`
- Grafana: `grafana/provisioning/`

### 시작 관련
- 자동 시작: `start-caspian.sh`
- 클러스터 생성: `setup-spoke-clusters.sh`
- 종료: `stop-caspian.sh`

---

이 문서는 프로젝트의 모든 파일과 디렉토리의 역할을 설명합니다.

**빠른 참조**:
- 시작: `bash start-caspian.sh`
- 문서: `README.md` → `QUICKSTART.md` → `시동_가이드.md`
